import urllib.request
from urllib.parse import urlparse
import re
import os
from datetime import datetime, timedelta, timezone
import random
import opencc
import socket
import time
import hashlib

# ======= é…ç½®åŒºåŸŸ ========
# åœ¨è¿™é‡Œä¿®æ”¹è¾“å…¥è¾“å‡ºè·¯å¾„å³å¯
SOURCE_BASE = "scripts/livesource6"
OUTPUT_BASE = "output/livesource6"

CONFIG = {
    # è¾“å…¥è·¯å¾„é…ç½®
    'source_base': SOURCE_BASE,
    'assets_dir': f"{SOURCE_BASE}",
    'blacklist_dir': f"{SOURCE_BASE}/blacklist",
    'main_channels_dir': f"{SOURCE_BASE}/ä¸»é¢‘é“", 
    'local_channels_dir': f"{SOURCE_BASE}/åœ°æ–¹å°",
    'manual_dir': f"{SOURCE_BASE}/æ‰‹å·¥åŒº",
    
    # è¾“å‡ºè·¯å¾„é…ç½®
    'output_base': OUTPUT_BASE,
    'output_dir': OUTPUT_BASE,
    'output_files': {
        'full': f'{OUTPUT_BASE}/full.txt',
        'lite': f'{OUTPUT_BASE}/lite.txt', 
        'custom': f'{OUTPUT_BASE}/custom.txt',
        'others': f'{OUTPUT_BASE}/others.txt'
    },
    
    # å…¶ä»–é…ç½®ï¼ˆé€šå¸¸ä¸éœ€è¦ä¿®æ”¹ï¼‰
    'request_timeout': 10,
    'request_retries': 3,
    'request_backoff_factor': 1.5,
    
    'removal_list': [
        "_ç”µä¿¡", "ç”µä¿¡", "é«˜æ¸…", "é¢‘é“", "ï¼ˆHDï¼‰", "-HD", "è‹±é™†", "_ITV", "(åŒ—ç¾)", "(HK)", 
        "AKtv", "ã€ŒIPV4ã€", "ã€ŒIPV6ã€", "é¢‘é™†", "å¤‡é™†", "å£¹é™†", "è´°é™†", "åé™†", "è‚†é™†", 
        "ä¼é™†", "é™†é™†", "æŸ’é™†", "é¢‘æ™´", "é¢‘ç²¤", "[è¶…æ¸…]", "é«˜æ¸…", "è¶…æ¸…", "æ ‡æ¸…", "æ–¯ç‰¹",
        "ç²¤é™†", "å›½é™†", "è‚†æŸ’", "é¢‘è‹±", "é¢‘ç‰¹", "é¢‘å›½", "é¢‘å£¹", "é¢‘è´°", "è‚†è´°", "é¢‘æµ‹",
        "å’ªå’•", "é—½ç‰¹", "é«˜ç‰¹", "é¢‘é«˜", "é¢‘æ ‡", "æ±é˜³"
    ],
    
    'critical_files': ['full.txt', 'custom.txt'],
    'url_patterns_to_skip': ['tvbus://', '/udp/', 'rtsp://', 'rtp://']
}

# ====== åˆå§‹åŒ–è®¾ç½® ======
os.makedirs(CONFIG['output_dir'], exist_ok=True)
# ä½¿ç”¨åŒ—äº¬æ—¶é—´
beijing_tz = timezone(timedelta(hours=8))
timestart = datetime.now(beijing_tz)

print(f"ğŸš€ å¼€å§‹å¤„ç†ç›´æ’­æº - è¾“å…¥: {CONFIG['source_base']}, è¾“å‡º: {CONFIG['output_base']}")

# ====== æ ¸å¿ƒå·¥å…·å‡½æ•° ======
def read_txt_to_array(file_name):
    """è¯»å–æ–‡æœ¬æ–‡ä»¶åˆ°æ•°ç»„"""
    try:
        with open(file_name, 'r', encoding='utf-8') as file:
            return [line.strip() for line in file if line.strip()]
    except FileNotFoundError:
        print(f"âš ï¸ æ–‡ä»¶æœªæ‰¾åˆ°: {file_name}")
        return []
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶é”™è¯¯ {file_name}: {e}")
        return []

def traditional_to_simplified(text: str) -> str:
    """ç¹ä½“è½¬ç®€ä½“"""
    try:
        converter = opencc.OpenCC('t2s')
        return converter.convert(text)
    except Exception as e:
        print(f"âŒ ç¹ç®€è½¬æ¢é”™è¯¯: {e}")
        return text

def read_blacklist_from_txt(file_path):
    """è¯»å–é»‘åå•"""
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            return [line.split(',')[1].strip() for line in file if ',' in line]
    except Exception as e:
        print(f"âŒ è¯»å–é»‘åå•é”™è¯¯ {file_path}: {e}")
        return []

def get_url_hash(url):
    """è·å–URLçš„å“ˆå¸Œå€¼ç”¨äºå»é‡"""
    return hashlib.md5(url.encode('utf-8')).hexdigest()

def should_skip_url(url):
    """æ£€æŸ¥URLæ˜¯å¦åº”è¯¥è·³è¿‡"""
    return any(pattern in url for pattern in CONFIG['url_patterns_to_skip'])

# ====== é»‘åå•å¤„ç† ======
print("ğŸ”§ åŠ è½½é»‘åå•...")
blacklist_auto = read_blacklist_from_txt(f"{CONFIG['blacklist_dir']}/blacklist_auto.txt") 
blacklist_manual = read_blacklist_from_txt(f"{CONFIG['blacklist_dir']}/blacklist_manual.txt") 
combined_blacklist = set(blacklist_auto + blacklist_manual)
print(f"âœ… é»‘åå•åŠ è½½å®Œæˆ: {len(combined_blacklist)} æ¡è®°å½•")

# ====== æ•°æ®å­˜å‚¨å®¹å™¨ ======
# ä¸»é¢‘é“
yangshi_lines = [] #CCTV
weishi_lines = [] #å«è§†é¢‘é“

# åœ°æ–¹å°
beijing_lines = [] #åœ°æ–¹å°-åŒ—äº¬é¢‘é“
shanghai_lines = [] #åœ°æ–¹å°-ä¸Šæµ·é¢‘é“
tianjin_lines = [] #åœ°æ–¹å°-å¤©æ´¥é¢‘é“
chongqing_lines = [] #åœ°æ–¹å°-é‡åº†é¢‘é“
guangdong_lines = [] #åœ°æ–¹å°-å¹¿ä¸œé¢‘é“
jiangsu_lines = [] #åœ°æ–¹å°-æ±Ÿè‹é¢‘é“
zhejiang_lines = [] #åœ°æ–¹å°-æµ™æ±Ÿé¢‘é“
shandong_lines = [] #åœ°æ–¹å°-å±±ä¸œé¢‘é“
henan_lines = [] #åœ°æ–¹å°-æ²³å—é¢‘é“
sichuan_lines = [] #åœ°æ–¹å°-å››å·é¢‘é“
hebei_lines = [] #åœ°æ–¹å°-æ²³åŒ—é¢‘é“
hunan_lines = [] #åœ°æ–¹å°-æ¹–å—é¢‘é“
hubei_lines = [] #åœ°æ–¹å°-æ¹–åŒ—é¢‘é“
anhui_lines = [] #åœ°æ–¹å°-å®‰å¾½é¢‘é“
fujian_lines = [] #åœ°æ–¹å°-ç¦å»ºé¢‘é“
shanxi1_lines = [] #åœ°æ–¹å°-é™•è¥¿é¢‘é“
liaoning_lines = [] #åœ°æ–¹å°-è¾½å®é¢‘é“
jiangxi_lines = [] #åœ°æ–¹å°-æ±Ÿè¥¿é¢‘é“
heilongjiang_lines = [] #åœ°æ–¹å°-é»‘é¾™æ±Ÿé¢‘é“
jilin_lines = [] #åœ°æ–¹å°-å‰æ—é¢‘é“
shanxi2_lines = [] #åœ°æ–¹å°-å±±è¥¿é¢‘é“
guangxi_lines = [] #åœ°æ–¹å°-å¹¿è¥¿é¢‘é“
yunnan_lines = [] #åœ°æ–¹å°-äº‘å—é¢‘é“
guizhou_lines = [] #åœ°æ–¹å°-è´µå·é¢‘é“
gansu_lines = [] #åœ°æ–¹å°-ç”˜è‚ƒé¢‘é“
neimenggu_lines = [] #åœ°æ–¹å°-å†…è’™é¢‘é“
xinjiang_lines = [] #åœ°æ–¹å°-æ–°ç–†é¢‘é“
hainan_lines = [] #åœ°æ–¹å°-æµ·å—é¢‘é“
ningxia_lines = [] #åœ°æ–¹å°-å®å¤é¢‘é“
qinghai_lines = [] #åœ°æ–¹å°-é’æµ·é¢‘é“
xizang_lines = [] #åœ°æ–¹å°-è¥¿è—é¢‘é“

# ä¸“ä¸šé¢‘é“
news_lines = [] #æ–°é—»é¢‘é“
shuzi_lines = [] #æ•°å­—é¢‘é“
dianying_lines = [] #ç”µå½±é¢‘é“
jieshuo_lines = [] #è§£è¯´é¢‘é“
zongyi_lines = [] #ç»¼è‰ºé¢‘é“
huya_lines = [] #è™ç‰™ç›´æ’­
douyu_lines = [] #æ–—é±¼ç›´æ’­
xianggang_lines = [] #é¦™æ¸¯é¢‘é“
aomen_lines = [] #æ¾³é—¨é¢‘é“
china_lines = [] #ä¸­å›½é¢‘é“
guoji_lines = [] #å›½é™…é¢‘é“
gangaotai_lines = [] #æ¸¯æ¾³å°
dianshiju_lines = [] #ç”µè§†å‰§
radio_lines = [] #æ”¶éŸ³æœº
donghuapian_lines = [] #åŠ¨ç”»ç‰‡
jilupian_lines = [] #è®°å½•ç‰‡
tiyu_lines = [] #ä½“è‚²é¢‘é“
tiyusaishi_lines = [] #ä½“è‚²èµ›äº‹
youxi_lines = [] #æ¸¸æˆé¢‘é“
xiqu_lines = [] #æˆæ›²é¢‘é“
yinyue_lines = [] #éŸ³ä¹é¢‘é“
chunwan_lines = [] #æ˜¥æ™šé¢‘é“
zhibozhongguo_lines = [] #ç›´æ’­ä¸­å›½

# å…¶ä»–åˆ†ç±»
others_lines = []
others_lines_url = [] # ä¸ºé™ä½others_æ–‡ä»¶å¤§å°ï¼Œå‰”é™¤é‡å¤urlæ·»åŠ 
aktv_lines = [] # AKTVé¢‘é“

# ====== é¢‘é“åç§°å¤„ç†å‡½æ•° ======
def clean_channel_name(channel_name, removal_list):
    """æ¸…ç†é¢‘é“åç§°ä¸­çš„ç‰¹å®šå­—ç¬¦"""
    for item in removal_list:
        channel_name = channel_name.replace(item, "")
    
    if channel_name.endswith("HD"):
        channel_name = channel_name[:-2]
    if channel_name.endswith("å°") and len(channel_name) > 3:
        channel_name = channel_name[:-1]
    
    return channel_name.strip()

def process_name_string(input_str):
    """å¤„ç†é¢‘é“åç§°å­—ç¬¦ä¸²"""
    try:
        parts = input_str.split(',')
        processed_parts = []
        
        for part in parts:
            if "CCTV" in part and "://" not in part:
                part = part.replace("IPV6", "").replace("PLUS", "+").replace("1080", "")
                filtered_str = ''.join(char for char in part if char.isdigit() or char in 'K+')
                
                if not filtered_str.strip():
                    filtered_str = part.replace("CCTV", "")
                
                if len(filtered_str) > 2 and re.search(r'4K|8K', filtered_str):
                    filtered_str = re.sub(r'(4K|8K).*', r'\1', filtered_str)
                    if len(filtered_str) > 2: 
                        filtered_str = re.sub(r'(4K|8K)', r'(\1)', filtered_str)
                
                processed_parts.append("CCTV" + filtered_str)
            elif "å«è§†" in part:
                processed_parts.append(re.sub(r'å«è§†ã€Œ.*ã€', 'å«è§†', part))
            else:
                processed_parts.append(part)
        
        return ','.join(processed_parts)
    except Exception as e:
        print(f"âŒ å¤„ç†é¢‘é“åç§°é”™è¯¯: {e}, è¾“å…¥: {input_str}")
        return input_str

# ====== URLå¤„ç†å‡½æ•° ======
def get_url_file_extension(url):
    """è·å–URLæ–‡ä»¶æ‰©å±•å"""
    try:
        parsed_url = urlparse(url)
        return os.path.splitext(parsed_url.path)[1]
    except Exception as e:
        print(f"âŒ è§£æURLæ‰©å±•åé”™è¯¯: {e}")
        return ""

def clean_url(url):
    """æ¸…ç†URLä¸­çš„$ç¬¦å·åŠä¹‹åå†…å®¹"""
    try:
        last_dollar_index = url.rfind('$')
        return url[:last_dollar_index] if last_dollar_index != -1 else url
    except Exception as e:
        print(f"âŒ æ¸…ç†URLé”™è¯¯: {e}")
        return url

def check_url_existence(data_list, url):
    """æ£€æŸ¥URLæ˜¯å¦å·²å­˜åœ¨"""
    try:
        urls = [item.split(',')[1] for item in data_list if ',' in item]
        return url not in urls
    except Exception as e:
        print(f"âŒ æ£€æŸ¥URLå­˜åœ¨æ€§é”™è¯¯: {e}")
        return True

def convert_m3u_to_txt(m3u_content):
    """M3Uæ ¼å¼è½¬TXTæ ¼å¼"""
    try:
        lines = m3u_content.split('\n')
        txt_lines = []
        channel_name = ""
        
        for line in lines:
            if line.startswith("#EXTM3U"):
                continue
            elif line.startswith("#EXTINF"):
                channel_name = line.split(',')[-1].strip()
            elif line.startswith(("http", "rtmp", "p3p")):
                if channel_name:
                    txt_lines.append(f"{channel_name},{line.strip()}")
            
            if "#genre#" not in line and "," in line and "://" in line:
                pattern = r'^[^,]+,[^\s]+://[^\s]+$'
                if bool(re.match(pattern, line)):
                    txt_lines.append(line)
        
        return '\n'.join(txt_lines)
    except Exception as e:
        print(f"âŒ è½¬æ¢M3Uåˆ°TXTé”™è¯¯: {e}")
        return m3u_content

# ====== ç½‘ç»œè¯·æ±‚å‡½æ•° ======
def get_http_response(url, timeout=None, retries=None, backoff_factor=None):
    """å¸¦é‡è¯•çš„HTTPè¯·æ±‚"""
    timeout = timeout or CONFIG['request_timeout']
    retries = retries or CONFIG['request_retries']
    backoff_factor = backoff_factor or CONFIG['request_backoff_factor']
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    }
    
    for attempt in range(retries):
        try:
            req = urllib.request.Request(url, headers=headers)
            with urllib.request.urlopen(req, timeout=timeout) as response:
                data = response.read()
                return data.decode('utf-8')
        except urllib.error.HTTPError as e:
            print(f"âŒ [HTTPé”™è¯¯] ä»£ç : {e.code}, URL: {url}")
            break
        except urllib.error.URLError as e:
            print(f"âš ï¸ [URLé”™è¯¯] åŸå› : {e.reason}, å°è¯•: {attempt + 1}/{retries}")
        except socket.timeout:
            print(f"â° [è¶…æ—¶] URL: {url}, å°è¯•: {attempt + 1}/{retries}")
        except Exception as e:
            print(f"âš ï¸ [å¼‚å¸¸] {type(e).__name__}: {e}, å°è¯•: {attempt + 1}/{retries}")
        
        if attempt < retries - 1:
            sleep_time = backoff_factor * (2 ** attempt)
            print(f"â³ ç­‰å¾… {sleep_time} ç§’åé‡è¯•...")
            time.sleep(sleep_time)
    
    return None

# ====== æ ¸å¿ƒåˆ†å‘é€»è¾‘ ======
def process_channel_line(line):
    """å¤„ç†å•è¡Œé¢‘é“æ•°æ®å¹¶åˆ†ç±» - æ”¯æŒåŒé¢‘é“å¤šåˆ†ç±»ä¸”å»é‡"""
    try:
        if "#genre#" not in line and "#EXTINF:" not in line and "," in line and "://" in line:
            channel_name = line.split(',')[0].strip()
            original_name = channel_name  # ä¿å­˜åŸå§‹åç§°
            channel_name = clean_channel_name(channel_name, CONFIG['removal_list'])
            channel_name = traditional_to_simplified(channel_name)
            channel_address = clean_url(line.split(',')[1].strip())
            
            # è·³è¿‡é»‘åå•å’Œç‰¹å®šåè®®
            if channel_address in combined_blacklist or should_skip_url(channel_address):
                return

            url_hash = get_url_hash(channel_address)
            processed_line = channel_name + "," + channel_address

            # ä¸»é¢‘é“åˆ†å‘ - æ”¯æŒåŒé¢‘é“å¤šåˆ†ç±»
            channel_added = False
            
            if "CCTV" in channel_name and check_url_existence(yangshi_lines, channel_address):
                yangshi_lines.append(process_name_string(processed_line))
                channel_added = True
            
            if channel_name in weishi_dictionary and check_url_existence(weishi_lines, channel_address):
                weishi_lines.append(process_name_string(processed_line))
                channel_added = True
            
            # åœ°æ–¹å°åˆ†å‘ - æ”¯æŒåŒé¢‘é“å¤šåˆ†ç±»
            if channel_name in beijing_dictionary and check_url_existence(beijing_lines, channel_address):
                beijing_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in shanghai_dictionary and check_url_existence(shanghai_lines, channel_address):
                shanghai_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in tianjin_dictionary and check_url_existence(tianjin_lines, channel_address):
                tianjin_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in chongqing_dictionary and check_url_existence(chongqing_lines, channel_address):
                chongqing_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in guangdong_dictionary and check_url_existence(guangdong_lines, channel_address):
                guangdong_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in jiangsu_dictionary and check_url_existence(jiangsu_lines, channel_address):
                jiangsu_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in zhejiang_dictionary and check_url_existence(zhejiang_lines, channel_address):
                zhejiang_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in shandong_dictionary and check_url_existence(shandong_lines, channel_address):
                shandong_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in henan_dictionary and check_url_existence(henan_lines, channel_address):
                henan_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in sichuan_dictionary and check_url_existence(sichuan_lines, channel_address):
                sichuan_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in hebei_dictionary and check_url_existence(hebei_lines, channel_address):
                hebei_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in hunan_dictionary and check_url_existence(hunan_lines, channel_address):
                hunan_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in hubei_dictionary and check_url_existence(hubei_lines, channel_address):
                hubei_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in anhui_dictionary and check_url_existence(anhui_lines, channel_address):
                anhui_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in fujian_dictionary and check_url_existence(fujian_lines, channel_address):
                fujian_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in shanxi1_dictionary and check_url_existence(shanxi1_lines, channel_address):
                shanxi1_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in liaoning_dictionary and check_url_existence(liaoning_lines, channel_address):
                liaoning_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in jiangxi_dictionary and check_url_existence(jiangxi_lines, channel_address):
                jiangxi_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in heilongjiang_dictionary and check_url_existence(heilongjiang_lines, channel_address):
                heilongjiang_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in jilin_dictionary and check_url_existence(jilin_lines, channel_address):
                jilin_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in shanxi2_dictionary and check_url_existence(shanxi2_lines, channel_address):
                shanxi2_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in guangxi_dictionary and check_url_existence(guangxi_lines, channel_address):
                guangxi_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in yunnan_dictionary and check_url_existence(yunnan_lines, channel_address):
                yunnan_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in guizhou_dictionary and check_url_existence(guizhou_lines, channel_address):
                guizhou_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in gansu_dictionary and check_url_existence(gansu_lines, channel_address):
                gansu_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in neimenggu_dictionary and check_url_existence(neimenggu_lines, channel_address):
                neimenggu_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in xinjiang_dictionary and check_url_existence(xinjiang_lines, channel_address):
                xinjiang_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in hainan_dictionary and check_url_existence(hainan_lines, channel_address):
                hainan_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in ningxia_dictionary and check_url_existence(ningxia_lines, channel_address):
                ningxia_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in qinghai_dictionary and check_url_existence(qinghai_lines, channel_address):
                qinghai_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in xizang_dictionary and check_url_existence(xizang_lines, channel_address):
                xizang_lines.append(process_name_string(processed_line))
                channel_added = True
            
            # ä¸“ä¸šé¢‘é“åˆ†å‘
            if channel_name in news_dictionary and check_url_existence(news_lines, channel_address):
                news_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in shuzi_dictionary and check_url_existence(shuzi_lines, channel_address):
                shuzi_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in dianying_dictionary and check_url_existence(dianying_lines, channel_address):
                dianying_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in jieshuo_dictionary and check_url_existence(jieshuo_lines, channel_address):
                jieshuo_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in zongyi_dictionary and check_url_existence(zongyi_lines, channel_address):
                zongyi_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in huya_dictionary and check_url_existence(huya_lines, channel_address):
                huya_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in douyu_dictionary and check_url_existence(douyu_lines, channel_address):
                douyu_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in xianggang_dictionary and check_url_existence(xianggang_lines, channel_address):
                xianggang_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in aomen_dictionary and check_url_existence(aomen_lines, channel_address):
                aomen_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in china_dictionary and check_url_existence(china_lines, channel_address):
                china_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in guoji_dictionary and check_url_existence(guoji_lines, channel_address):
                guoji_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in gangaotai_dictionary and check_url_existence(gangaotai_lines, channel_address):
                gangaotai_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in dianshiju_dictionary and check_url_existence(dianshiju_lines, channel_address):
                dianshiju_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in radio_dictionary and check_url_existence(radio_lines, channel_address):
                radio_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in donghuapian_dictionary and check_url_existence(donghuapian_lines, channel_address):
                donghuapian_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in jilupian_dictionary and check_url_existence(jilupian_lines, channel_address):
                jilupian_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in tiyu_dictionary and check_url_existence(tiyu_lines, channel_address):
                tiyu_lines.append(process_name_string(processed_line))
                channel_added = True
            
            if any(tiyusaishi_item in channel_name for tiyusaishi_item in tiyusaishi_dictionary) and check_url_existence(tiyusaishi_lines, channel_address):
                tiyusaishi_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in youxi_dictionary and check_url_existence(youxi_lines, channel_address):
                youxi_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in xiqu_dictionary and check_url_existence(xiqu_lines, channel_address):
                xiqu_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in yinyue_dictionary and check_url_existence(yinyue_lines, channel_address):
                yinyue_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in chunwan_dictionary and check_url_existence(chunwan_lines, channel_address):
                chunwan_lines.append(process_name_string(processed_line))
                channel_added = True
                
            if channel_name in zhibozhongguo_dictionary and check_url_existence(zhibozhongguo_lines, channel_address):
                zhibozhongguo_lines.append(process_name_string(processed_line))
                channel_added = True
            
            # å…¶ä»–é¢‘é“åˆ†å‘ - ä½¿ç”¨URLå“ˆå¸Œå»é‡
            if not channel_added and url_hash not in others_lines_url:
                others_lines_url.append(url_hash)
                others_lines.append(processed_line)

                
    except Exception as e:
        print(f"âŒ å¤„ç†é¢‘é“è¡Œé”™è¯¯: {e}, è¡Œå†…å®¹: {line}")

def process_url(url):
    """å¤„ç†å•ä¸ªURLæº"""
    try:
        print(f"ğŸŒ å¤„ç†URL: {url}")
        others_lines.append(f"â—†â—†â—† {url}")
        
        response_text = get_http_response(url)
        if not response_text:
            print(f"âŒ è·å–URLå†…å®¹å¤±è´¥: {url}")
            others_lines.append(f"âŒ è·å–å¤±è´¥: {url}\n")
            return

        # æ£€æŸ¥æ˜¯å¦ä¸ºM3Uæ ¼å¼
        is_m3u = response_text.startswith("#EXTM3U") or response_text.startswith("#EXTINF")
        if get_url_file_extension(url) in [".m3u", ".m3u8"] or is_m3u:
            response_text = convert_m3u_to_txt(response_text)

        lines = response_text.split('\n')
        valid_lines = 0
        
        for line in lines:
            if ("#genre#" not in line and "," in line and "://" in line and 
                not should_skip_url(line)):
                
                try:
                    channel_name, channel_address = line.split(',', 1)
                    
                    # å¤„ç†å¸¦#å·çš„åŠ é€Ÿæº
                    if "#" not in channel_address:
                        process_channel_line(line)
                        valid_lines += 1
                    else:
                        url_list = channel_address.split('#')
                        for channel_url in url_list:
                            process_channel_line(f'{channel_name},{channel_url}')
                            valid_lines += 1
                except Exception as e:
                    print(f"âš ï¸ å¤„ç†è¡Œé”™è¯¯: {e}, è¡Œ: {line}")

        print(f"âœ… å¤„ç†å®Œæˆ: {valid_lines} ä¸ªæœ‰æ•ˆé¢‘é“")
        others_lines.append(f"âœ… å®Œæˆ: {valid_lines} ä¸ªé¢‘é“\n")

    except Exception as e:
        print(f"âŒ å¤„ç†URLæ—¶å‘ç”Ÿé”™è¯¯ {url}: {e}")
        others_lines.append(f"âŒ é”™è¯¯: {e}\n")

# ====== æ•°æ®æ’åºå’Œçº é”™ ======
def load_corrections_name(filename):
    """åŠ è½½é¢‘é“åç§°çº é”™æ•°æ®"""
    corrections = {}
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            for line in f:
                if not line.strip():
                    continue
                parts = line.strip().split(',')
                if len(parts) >= 2:
                    correct_name = parts[0]
                    for name in parts[1:]:
                        corrections[name] = correct_name
        print(f"âœ… çº é”™æ•°æ®åŠ è½½: {len(corrections)} æ¡è§„åˆ™")
    except Exception as e:
        print(f"âŒ åŠ è½½çº é”™æ•°æ®é”™è¯¯ {filename}: {e}")
    return corrections

def correct_name_data(corrections, data):
    """çº æ­£é¢‘é“åç§°"""
    corrected_data = []
    for line in data:
        try:
            if ',' not in line:
                continue
            name, url = line.split(',', 1)
            if name in corrections and name != corrections[name]:
                name = corrections[name]
            corrected_data.append(f"{name},{url}")
        except Exception as e:
            print(f"âš ï¸ çº æ­£åç§°é”™è¯¯: {e}, è¡Œ: {line}")
    return corrected_data

def sort_data(order, data):
    """æŒ‰æŒ‡å®šé¡ºåºæ’åºæ•°æ®"""
    try:
        order_dict = {name: i for i, name in enumerate(order)}
        def sort_key(line):
            try:
                name = line.split(',')[0]
                return order_dict.get(name, len(order))
            except:
                return len(order)
        return sorted(data, key=sort_key)
    except Exception as e:
        print(f"âš ï¸ æ’åºæ•°æ®é”™è¯¯: {e}")
        return data

# ====== åŠ è½½å­—å…¸æ•°æ® ======
print("ğŸ“š åŠ è½½å­—å…¸æ•°æ®...")
# ä¸»é¢‘é“å­—å…¸
yangshi_dictionary = read_txt_to_array(f"{CONFIG['main_channels_dir']}/CCTV.txt")
weishi_dictionary = read_txt_to_array(f"{CONFIG['main_channels_dir']}/å«è§†é¢‘é“.txt")

# åœ°æ–¹å°å­—å…¸
beijing_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/åŒ—äº¬é¢‘é“.txt")
shanghai_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/ä¸Šæµ·é¢‘é“.txt")
tianjin_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/å¤©æ´¥é¢‘é“.txt")
chongqing_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/é‡åº†é¢‘é“.txt")
guangdong_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/å¹¿ä¸œé¢‘é“.txt")
jiangsu_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/æ±Ÿè‹é¢‘é“.txt")
zhejiang_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/æµ™æ±Ÿé¢‘é“.txt")
shandong_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/å±±ä¸œé¢‘é“.txt")
henan_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/æ²³å—é¢‘é“.txt")
sichuan_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/å››å·é¢‘é“.txt")
hebei_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/æ²³åŒ—é¢‘é“.txt")
hunan_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/æ¹–å—é¢‘é“.txt")
hubei_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/æ¹–åŒ—é¢‘é“.txt")
anhui_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/å®‰å¾½é¢‘é“.txt")
fujian_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/ç¦å»ºé¢‘é“.txt")
shanxi1_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/é™•è¥¿é¢‘é“.txt")
liaoning_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/è¾½å®é¢‘é“.txt")
jiangxi_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/æ±Ÿè¥¿é¢‘é“.txt")
heilongjiang_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/é»‘é¾™æ±Ÿé¢‘é“.txt")
jilin_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/å‰æ—é¢‘é“.txt")
shanxi2_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/å±±è¥¿é¢‘é“.txt")
guangxi_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/å¹¿è¥¿é¢‘é“.txt")
yunnan_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/äº‘å—é¢‘é“.txt")
guizhou_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/è´µå·é¢‘é“.txt")
gansu_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/ç”˜è‚ƒé¢‘é“.txt")
neimenggu_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/å†…è’™é¢‘é“.txt")
xinjiang_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/æ–°ç–†é¢‘é“.txt")
hainan_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/æµ·å—é¢‘é“.txt")
ningxia_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/å®å¤é¢‘é“.txt")
qinghai_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/é’æµ·é¢‘é“.txt")
xizang_dictionary = read_txt_to_array(f"{CONFIG['local_channels_dir']}/è¥¿è—é¢‘é“.txt")

# ä¸“ä¸šé¢‘é“å­—å…¸
news_dictionary = read_txt_to_array(f"{CONFIG['main_channels_dir']}/æ–°é—»é¢‘é“.txt")
shuzi_dictionary = read_txt_to_array(f"{CONFIG['main_channels_dir']}/æ•°å­—é¢‘é“.txt")
dianying_dictionary = read_txt_to_array(f"{CONFIG['main_channels_dir']}/ç”µå½±é¢‘é“.txt")
jieshuo_dictionary = read_txt_to_array(f"{CONFIG['main_channels_dir']}/è§£è¯´é¢‘é“.txt")
zongyi_dictionary = read_txt_to_array(f"{CONFIG['main_channels_dir']}/ç»¼è‰ºé¢‘é“.txt")
huya_dictionary = read_txt_to_array(f"{CONFIG['main_channels_dir']}/è™ç‰™ç›´æ’­.txt")
douyu_dictionary = read_txt_to_array(f"{CONFIG['main_channels_dir']}/æ–—é±¼ç›´æ’­.txt")
xianggang_dictionary = read_txt_to_array(f"{CONFIG['main_channels_dir']}/é¦™æ¸¯é¢‘é“.txt")
aomen_dictionary = read_txt_to_array(f"{CONFIG['main_channels_dir']}/æ¾³é—¨é¢‘é“.txt")
china_dictionary = read_txt_to_array(f"{CONFIG['main_channels_dir']}/ä¸­å›½é¢‘é“.txt")
guoji_dictionary = read_txt_to_array(f"{CONFIG['main_channels_dir']}/å›½é™…é¢‘é“.txt")
gangaotai_dictionary = read_txt_to_array(f"{CONFIG['main_channels_dir']}/æ¸¯æ¾³å°.txt")
dianshiju_dictionary = read_txt_to_array(f"{CONFIG['main_channels_dir']}/ç”µè§†å‰§.txt")
radio_dictionary = read_txt_to_array(f"{CONFIG['main_channels_dir']}/æ”¶éŸ³æœº.txt")
donghuapian_dictionary = read_txt_to_array(f"{CONFIG['main_channels_dir']}/åŠ¨ç”»ç‰‡.txt")
jilupian_dictionary = read_txt_to_array(f"{CONFIG['main_channels_dir']}/è®°å½•ç‰‡.txt")
tiyu_dictionary = read_txt_to_array(f"{CONFIG['main_channels_dir']}/ä½“è‚²é¢‘é“.txt")
tiyusaishi_dictionary = read_txt_to_array(f"{CONFIG['main_channels_dir']}/ä½“è‚²èµ›äº‹.txt")
youxi_dictionary = read_txt_to_array(f"{CONFIG['main_channels_dir']}/æ¸¸æˆé¢‘é“.txt")
xiqu_dictionary = read_txt_to_array(f"{CONFIG['main_channels_dir']}/æˆæ›²é¢‘é“.txt")
yinyue_dictionary = read_txt_to_array(f"{CONFIG['main_channels_dir']}/éŸ³ä¹é¢‘é“.txt")
chunwan_dictionary = read_txt_to_array(f"{CONFIG['main_channels_dir']}/æ˜¥æ™šé¢‘é“.txt")
zhibozhongguo_dictionary = read_txt_to_array(f"{CONFIG['main_channels_dir']}/ç›´æ’­ä¸­å›½.txt")

# åŠ è½½çº é”™æ•°æ®
corrections_name = load_corrections_name(f"{CONFIG['assets_dir']}/corrections_name.txt")

print(f"âœ… å­—å…¸æ•°æ®åŠ è½½å®Œæˆ: CCTV({len(yangshi_dictionary)}) å«è§†({len(weishi_dictionary)}) åœ°æ–¹å°(31ä¸ª) ä¸“ä¸šé¢‘é“(23ä¸ª)")

# ====== ä¸»å¤„ç†æµç¨‹ ======
def main():
    print("ğŸš€ å¼€å§‹å¤„ç†ç›´æ’­æº...")
    
    # 1. å¤„ç†URLæº
    urls = read_txt_to_array(f"{CONFIG['assets_dir']}/urls-daily.txt")
    print(f"ğŸ“¡ å‘ç° {len(urls)} ä¸ªURLæº")
    
    for url in urls:
        if url.startswith("http"):
            # å¤„ç†æ—¥æœŸå˜é‡ - ä½¿ç”¨åŒ—äº¬æ—¶é—´
            current_date_str = datetime.now(beijing_tz).strftime("%m%d")
            yesterday_date_str = (datetime.now(beijing_tz) - timedelta(days=1)).strftime("%m%d")
            
            if "{MMdd}" in url:
                url = url.replace("{MMdd}", current_date_str)
            if "{MMdd-1}" in url:
                url = url.replace("{MMdd-1}", yesterday_date_str)
            
            process_url(url)

    # 2. å¤„ç†ç™½åå•
    print("ğŸ“‹ å¤„ç†ç™½åå•...")
    whitelist_auto_lines = read_txt_to_array(f"{CONFIG['blacklist_dir']}/whitelist_auto.txt")
    whitelist_count = 0
    for whitelist_line in whitelist_auto_lines:
        if ("#genre#" not in whitelist_line and "," in whitelist_line and 
            "://" in whitelist_line):
            whitelist_parts = whitelist_line.split(",")
            try:
                response_time = float(whitelist_parts[0].replace("ms", ""))
            except ValueError:
                response_time = 60000
            if response_time < 2000:  # 2ç§’ä»¥å†…çš„é«˜å“åº”æº
                process_channel_line(",".join(whitelist_parts[1:]))
                whitelist_count += 1
    print(f"âœ… ç™½åå•å¤„ç†å®Œæˆ: {whitelist_count} ä¸ªé«˜é€Ÿæº")

    # 3. å¤„ç†æ‰‹å·¥åŒº
    print("ğŸ”§ å¤„ç†æ‰‹å·¥åŒº...")
    # å¤„ç†æ‰€æœ‰æ‰‹å·¥åŒºæ–‡ä»¶
    manual_files = {
        'å¹¿ä¸œé¢‘é“': guangdong_lines,
        'æ¹–åŒ—é¢‘é“': hubei_lines, 
        'æ¹–å—é¢‘é“': hunan_lines,
        'æµ™æ±Ÿé¢‘é“': zhejiang_lines,
        'æ±Ÿè‹é¢‘é“': jiangsu_lines
    }

    for region, target_list in manual_files.items():
        manual_file = f"{CONFIG['manual_dir']}/{region}.txt"
        if os.path.exists(manual_file):
            manual_data = read_txt_to_array(manual_file)
            for line in manual_data:
                if "," in line and "://" in line:
                    process_channel_line(line)  # ä½¿ç”¨ç›¸åŒçš„å¤„ç†é€»è¾‘ç¡®ä¿å»é‡
            print(f"âœ… æ‰‹å·¥åŒº {region}: {len(manual_data)} æ¡è®°å½•")

    # 4. å¤„ç†AKTV
    print("ğŸŒ å¤„ç†AKTV...")
    aktv_url = "https://aktv.space/live.m3u"
    aktv_text = get_http_response(aktv_url)
    if aktv_text:
        print("âœ… AKTVæˆåŠŸè·å–å†…å®¹")
        aktv_text = convert_m3u_to_txt(aktv_text)
        aktv_lines.extend(aktv_text.strip().split('\n'))
    else:
        print("âš ï¸ AKTVè¯·æ±‚å¤±è´¥ï¼Œä»æœ¬åœ°è·å–ï¼")
        aktv_lines.extend(read_txt_to_array(f"{CONFIG['manual_dir']}/AKTV.txt"))
    print(f"âœ… AKTVå¤„ç†å®Œæˆ: {len(aktv_lines)} ä¸ªé¢‘é“")

    # 5. å¤„ç†ä½“è‚²èµ›äº‹æ—¥æœŸæ ¼å¼
    def normalize_date_to_md(text):
        """æ—¥æœŸæ ¼å¼æ ‡å‡†åŒ–"""
        try:
            text = text.strip()
            def format_md(m):
                month = int(m.group(1))
                day = int(m.group(2))
                after = m.group(3) or ''
                if not after.startswith(' '):
                    after = ' ' + after
                return f"{month}-{day}{after}"

            text = re.sub(r'^0?(\d{1,2})/0?(\d{1,2})(.*)', format_md, text)
            text = re.sub(r'^\d{4}-0?(\d{1,2})-0?(\d{1,2})(.*)', format_md, text)
            text = re.sub(r'^0?(\d{1,2})æœˆ0?(\d{1,2})æ—¥(.*)', format_md, text)
            return text
        except Exception as e:
            print(f"âš ï¸ æ—¥æœŸæ ¼å¼åŒ–é”™è¯¯: {e}, æ–‡æœ¬: {text}")
            return text

    normalized_tiyusaishi_lines = [normalize_date_to_md(s) for s in tiyusaishi_lines]

    # 6. ç”Ÿæˆç‰ˆæœ¬ä¿¡æ¯ - ä½¿ç”¨åŒ—äº¬æ—¶é—´
    beijing_time = datetime.now(beijing_tz)
    formatted_time = beijing_time.strftime("%Y%m%d %H:%M:%S")

    def get_random_url(file_path):
        """éšæœºè·å–URL"""
        urls = []
        try:
            with open(file_path, 'r', encoding='utf-8') as file:
                for line in file:
                    url = line.strip().split(',')[-1]
                    urls.append(url)    
        except Exception as e:
            print(f"âš ï¸ è¯»å–æ–‡ä»¶ {file_path} æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")
        return random.choice(urls) if urls else ""

    version = formatted_time + "," + get_random_url(f"{CONFIG['manual_dir']}/ä»Šæ—¥æ¨å°.txt")
    about = "xiaoranmuze," + get_random_url(f"{CONFIG['manual_dir']}/ä»Šæ—¥æ¨å°.txt")
    daily_mtv = "ä»Šæ—¥æ¨è," + get_random_url(f"{CONFIG['manual_dir']}/ä»Šæ—¥æ¨è.txt")
    daily_mtv1 = "ğŸ”¥ä½è°ƒ," + get_random_url(f"{CONFIG['manual_dir']}/ä»Šæ—¥æ¨è.txt")
    daily_mtv2 = "ğŸ”¥ä½¿ç”¨," + get_random_url(f"{CONFIG['manual_dir']}/ä»Šæ—¥æ¨è.txt")
    daily_mtv3 = "ğŸ”¥ç¦æ­¢," + get_random_url(f"{CONFIG['manual_dir']}/ä»Šæ—¥æ¨è.txt")
    daily_mtv4 = "ğŸ”¥è´©å–," + get_random_url(f"{CONFIG['manual_dir']}/ä»Šæ—¥æ¨è.txt")

    # 7. ç”Ÿæˆè¾“å‡ºæ–‡ä»¶
    print("ğŸ“„ ç”Ÿæˆè¾“å‡ºæ–‡ä»¶...")

    # å…¨éƒ¨æº (full.txt)
    all_lines_full = []
    all_lines_full.extend(["ğŸŒå¤®è§†é¢‘é“,#genre#"] + sort_data(yangshi_dictionary, correct_name_data(corrections_name, yangshi_lines)) + ['\n'])
    all_lines_full.extend(["ğŸ“¡å«è§†é¢‘é“,#genre#"] + sort_data(weishi_dictionary, correct_name_data(corrections_name, weishi_lines)) + ['\n'])

    # åœ°æ–¹å°åˆ†ç±»
    all_lines_full.extend(["â˜˜ï¸åŒ—äº¬é¢‘é“,#genre#"] + sort_data(beijing_dictionary, correct_name_data(corrections_name, beijing_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸ä¸Šæµ·é¢‘é“,#genre#"] + sort_data(shanghai_dictionary, correct_name_data(corrections_name, shanghai_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸å¤©æ´¥é¢‘é“,#genre#"] + sort_data(tianjin_dictionary, correct_name_data(corrections_name, tianjin_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸é‡åº†é¢‘é“,#genre#"] + sort_data(chongqing_dictionary, correct_name_data(corrections_name, chongqing_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸å¹¿ä¸œé¢‘é“,#genre#"] + sort_data(guangdong_dictionary, correct_name_data(corrections_name, guangdong_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸æ±Ÿè‹é¢‘é“,#genre#"] + sort_data(jiangsu_dictionary, correct_name_data(corrections_name, jiangsu_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸æµ™æ±Ÿé¢‘é“,#genre#"] + sort_data(zhejiang_dictionary, correct_name_data(corrections_name, zhejiang_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸å±±ä¸œé¢‘é“,#genre#"] + sort_data(shandong_dictionary, correct_name_data(corrections_name, shandong_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸æ²³å—é¢‘é“,#genre#"] + sort_data(henan_dictionary, correct_name_data(corrections_name, henan_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸å››å·é¢‘é“,#genre#"] + sort_data(sichuan_dictionary, correct_name_data(corrections_name, sichuan_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸æ²³åŒ—é¢‘é“,#genre#"] + sort_data(hebei_dictionary, correct_name_data(corrections_name, hebei_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸æ¹–å—é¢‘é“,#genre#"] + sort_data(hunan_dictionary, correct_name_data(corrections_name, hunan_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸æ¹–åŒ—é¢‘é“,#genre#"] + sort_data(hubei_dictionary, correct_name_data(corrections_name, hubei_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸å®‰å¾½é¢‘é“,#genre#"] + sort_data(anhui_dictionary, correct_name_data(corrections_name, anhui_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸ç¦å»ºé¢‘é“,#genre#"] + sort_data(fujian_dictionary, correct_name_data(corrections_name, fujian_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸é™•è¥¿é¢‘é“,#genre#"] + sort_data(shanxi1_dictionary, correct_name_data(corrections_name, shanxi1_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸è¾½å®é¢‘é“,#genre#"] + sort_data(liaoning_dictionary, correct_name_data(corrections_name, liaoning_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸æ±Ÿè¥¿é¢‘é“,#genre#"] + sort_data(jiangxi_dictionary, correct_name_data(corrections_name, jiangxi_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸é»‘é¾™æ±Ÿå°,#genre#"] + sort_data(heilongjiang_dictionary, correct_name_data(corrections_name, heilongjiang_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸å‰æ—é¢‘é“,#genre#"] + sort_data(jilin_dictionary, correct_name_data(corrections_name, jilin_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸å±±è¥¿é¢‘é“,#genre#"] + sort_data(shanxi2_dictionary, correct_name_data(corrections_name, shanxi2_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸å¹¿è¥¿é¢‘é“,#genre#"] + sort_data(guangxi_dictionary, correct_name_data(corrections_name, guangxi_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸äº‘å—é¢‘é“,#genre#"] + sort_data(yunnan_dictionary, correct_name_data(corrections_name, yunnan_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸è´µå·é¢‘é“,#genre#"] + sort_data(guizhou_dictionary, correct_name_data(corrections_name, guizhou_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸ç”˜è‚ƒé¢‘é“,#genre#"] + sort_data(gansu_dictionary, correct_name_data(corrections_name, gansu_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸å†…è’™é¢‘é“,#genre#"] + sort_data(neimenggu_dictionary, correct_name_data(corrections_name, neimenggu_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸æ–°ç–†é¢‘é“,#genre#"] + sort_data(xinjiang_dictionary, correct_name_data(corrections_name, xinjiang_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸æµ·å—é¢‘é“,#genre#"] + sort_data(hainan_dictionary, correct_name_data(corrections_name, hainan_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸å®å¤é¢‘é“,#genre#"] + sort_data(ningxia_dictionary, correct_name_data(corrections_name, ningxia_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸é’æµ·é¢‘é“,#genre#"] + sort_data(qinghai_dictionary, correct_name_data(corrections_name, qinghai_lines)) + ['\n'])
    all_lines_full.extend(["â˜˜ï¸è¥¿è—é¢‘é“,#genre#"] + sort_data(xizang_dictionary, correct_name_data(corrections_name, xizang_lines)) + ['\n'])

    # ä¸“ä¸šé¢‘é“
    all_lines_full.extend(["ğŸ“°æ–°é—»é¢‘é“,#genre#"] + sort_data(news_dictionary, correct_name_data(corrections_name, news_lines)) + ['\n'])
    all_lines_full.extend(["ğŸï¸æ•°å­—é¢‘é“,#genre#"] + sort_data(shuzi_dictionary, correct_name_data(corrections_name, shuzi_lines)) + ['\n'])
    all_lines_full.extend(["ğŸ¬ç”µå½±é¢‘é“,#genre#"] + sort_data(dianying_dictionary, correct_name_data(corrections_name, dianying_lines)) + ['\n'])
    all_lines_full.extend(["ğŸ™ï¸è§£è¯´é¢‘é“,#genre#"] + sort_data(jieshuo_dictionary, correct_name_data(corrections_name, jieshuo_lines)) + ['\n'])
    all_lines_full.extend(["ğŸ¤ç»¼è‰ºé¢‘é“,#genre#"] + sort_data(zongyi_dictionary, correct_name_data(corrections_name, zongyi_lines)) + ['\n'])
    all_lines_full.extend(["ğŸ¯è™ç‰™ç›´æ’­,#genre#"] + sort_data(huya_dictionary, correct_name_data(corrections_name, huya_lines)) + ['\n'])
    all_lines_full.extend(["ğŸ¬æ–—é±¼ç›´æ’­,#genre#"] + sort_data(douyu_dictionary, correct_name_data(corrections_name, douyu_lines)) + ['\n'])
    all_lines_full.extend(["ğŸ‡­ğŸ‡°é¦™æ¸¯é¢‘é“,#genre#"] + sort_data(xianggang_dictionary, correct_name_data(corrections_name, xianggang_lines)) + ['\n'])
    all_lines_full.extend(["ğŸ‡²ğŸ‡´æ¾³é—¨é¢‘é“,#genre#"] + sort_data(aomen_dictionary, correct_name_data(corrections_name, aomen_lines)) + ['\n'])
    all_lines_full.extend(["ğŸ‡¨ğŸ‡³ä¸­å›½é¢‘é“,#genre#"] + sort_data(china_dictionary, correct_name_data(corrections_name, china_lines)) + ['\n'])
    all_lines_full.extend(["ğŸŒå›½é™…é¢‘é“,#genre#"] + sort_data(guoji_dictionary, correct_name_data(corrections_name, guoji_lines)) + ['\n'])
    all_lines_full.extend(["ğŸ‡¨ğŸ‡³æ¸¯æ¾³å°,#genre#"] + sort_data(gangaotai_dictionary, correct_name_data(corrections_name, gangaotai_lines)) + ['\n'])
    all_lines_full.extend(["ğŸ“ºç”µè§†å‰§,#genre#"] + sort_data(dianshiju_dictionary, correct_name_data(corrections_name, dianshiju_lines)) + ['\n'])
    all_lines_full.extend(["ğŸ“»æ”¶éŸ³æœº,#genre#"] + sort_data(radio_dictionary, correct_name_data(corrections_name, radio_lines)) + ['\n'])
    all_lines_full.extend(["ğŸ•åŠ¨ç”»ç‰‡,#genre#"] + sort_data(donghuapian_dictionary, correct_name_data(corrections_name, donghuapian_lines)) + ['\n'])
    all_lines_full.extend(["ğŸ“½ï¸è®°å½•ç‰‡,#genre#"] + sort_data(jilupian_dictionary, correct_name_data(corrections_name, jilupian_lines)) + ['\n'])
    all_lines_full.extend(["âš½ä½“è‚²é¢‘é“,#genre#"] + sort_data(tiyu_dictionary, correct_name_data(corrections_name, tiyu_lines)) + ['\n'])
    all_lines_full.extend(["ğŸ†ä½“è‚²èµ›äº‹,#genre#"] + normalized_tiyusaishi_lines + ['\n'])
    all_lines_full.extend(["ğŸ®æ¸¸æˆé¢‘é“,#genre#"] + sort_data(youxi_dictionary, correct_name_data(corrections_name, youxi_lines)) + ['\n'])
    all_lines_full.extend(["ğŸ­æˆæ›²é¢‘é“,#genre#"] + sort_data(xiqu_dictionary, correct_name_data(corrections_name, xiqu_lines)) + ['\n'])
    all_lines_full.extend(["ğŸµéŸ³ä¹é¢‘é“,#genre#"] + sort_data(yinyue_dictionary, correct_name_data(corrections_name, yinyue_lines)) + ['\n'])
    all_lines_full.extend(["ğŸ‰æ˜¥æ™šé¢‘é“,#genre#"] + sort_data(chunwan_dictionary, correct_name_data(corrections_name, chunwan_lines)) + ['\n'])
    all_lines_full.extend(["ğŸ“¡ç›´æ’­ä¸­å›½,#genre#"] + sort_data(zhibozhongguo_dictionary, correct_name_data(corrections_name, zhibozhongguo_lines)) + ['\n'])

    # å®Œæ•´ç‰ˆå…¶ä»–å’Œæ›´æ–°ä¿¡æ¯
    all_lines_full.extend(["ğŸ“¦å…¶å®ƒæº,#genre#"] + others_lines + ['\n'])
    all_lines_full.extend(["ğŸ•’æ›´æ–°æ—¶é—´,#genre#"] + [version, about, daily_mtv, daily_mtv1, daily_mtv2, daily_mtv3, daily_mtv4] + read_txt_to_array(f"{CONFIG['manual_dir']}/about.txt") + ['\n'])

    # ç²¾ç®€æº (lite.txt)
    all_lines_lite = []
    all_lines_lite.extend(["å¤®è§†é¢‘é“,#genre#"] + sort_data(yangshi_dictionary, correct_name_data(corrections_name, yangshi_lines)) + ['\n'])
    all_lines_lite.extend(["å«è§†é¢‘é“,#genre#"] + sort_data(weishi_dictionary, correct_name_data(corrections_name, weishi_lines)) + ['\n'])

    # åˆå¹¶åœ°æ–¹é¢‘é“
    all_lines_lite.extend(["åœ°æ–¹é¢‘é“,#genre#"] + 
                           sort_data(beijing_dictionary, correct_name_data(corrections_name, beijing_lines)) +
                           sort_data(shanghai_dictionary, correct_name_data(corrections_name, shanghai_lines)) +
                           sort_data(tianjin_dictionary, correct_name_data(corrections_name, tianjin_lines)) +
                           sort_data(chongqing_dictionary, correct_name_data(corrections_name, chongqing_lines)) +
                           sort_data(guangdong_dictionary, correct_name_data(corrections_name, guangdong_lines)) +
                           sort_data(jiangsu_dictionary, correct_name_data(corrections_name, jiangsu_lines)) +
                           sort_data(zhejiang_dictionary, correct_name_data(corrections_name, zhejiang_lines)) +
                           sort_data(shandong_dictionary, correct_name_data(corrections_name, shandong_lines)) +
                           sort_data(henan_dictionary, correct_name_data(corrections_name, henan_lines)) +
                           sort_data(sichuan_dictionary, correct_name_data(corrections_name, sichuan_lines)) +
                           sort_data(hebei_dictionary, correct_name_data(corrections_name, hebei_lines)) +
                           sort_data(hunan_dictionary, correct_name_data(corrections_name, hunan_lines)) +
                           sort_data(hubei_dictionary, correct_name_data(corrections_name, hubei_lines)) +
                           sort_data(anhui_dictionary, correct_name_data(corrections_name, anhui_lines)) +
                           sort_data(fujian_dictionary, correct_name_data(corrections_name, fujian_lines)) +
                           sort_data(shanxi1_dictionary, correct_name_data(corrections_name, shanxi1_lines)) +
                           sort_data(liaoning_dictionary, correct_name_data(corrections_name, liaoning_lines)) +
                           sort_data(jiangxi_dictionary, correct_name_data(corrections_name, jiangxi_lines)) +
                           sort_data(heilongjiang_dictionary, correct_name_data(corrections_name, heilongjiang_lines)) +
                           sort_data(jilin_dictionary, correct_name_data(corrections_name, jilin_lines)) +
                           sort_data(shanxi2_dictionary, correct_name_data(corrections_name, shanxi2_lines)) +
                           sort_data(guangxi_dictionary, correct_name_data(corrections_name, guangxi_lines)) +
                           sort_data(yunnan_dictionary, correct_name_data(corrections_name, yunnan_lines)) +
                           sort_data(guizhou_dictionary, correct_name_data(corrections_name, guizhou_lines)) +
                           sort_data(gansu_dictionary, correct_name_data(corrections_name, gansu_lines)) +
                           sort_data(neimenggu_dictionary, correct_name_data(corrections_name, neimenggu_lines)) +
                           sort_data(xinjiang_dictionary, correct_name_data(corrections_name, xinjiang_lines)) +
                           sort_data(hainan_dictionary, correct_name_data(corrections_name, hainan_lines)) +
                           sort_data(ningxia_dictionary, correct_name_data(corrections_name, ningxia_lines)) +
                           sort_data(qinghai_dictionary, correct_name_data(corrections_name, qinghai_lines)) +
                           sort_data(xizang_dictionary, correct_name_data(corrections_name, xizang_lines)) + ['\n'])

    # ç²¾ç®€æºæ›´æ–°ä¿¡æ¯
    all_lines_lite.extend(["æ›´æ–°æ—¶é—´,#genre#"] + [version] + ['\n'])

    # å®šåˆ¶æº (custom.txt)
    all_lines_custom = []
    all_lines_custom.extend(["ğŸŒå¤®è§†é¢‘é“,#genre#"] + sort_data(yangshi_dictionary, correct_name_data(corrections_name, yangshi_lines)) + ['\n'])
    all_lines_custom.extend(["ğŸ“¡å«è§†é¢‘é“,#genre#"] + sort_data(weishi_dictionary, correct_name_data(corrections_name, weishi_lines)) + ['\n'])

    # å®šåˆ¶æºçš„åœ°æ–¹é¢‘é“
    all_lines_custom.extend(["ğŸ åœ°æ–¹é¢‘é“,#genre#"] + 
                           sort_data(hubei_dictionary, correct_name_data(corrections_name, hubei_lines)) +
                           sort_data(shanghai_dictionary, correct_name_data(corrections_name, shanghai_lines)) +
                           sort_data(zhejiang_dictionary, correct_name_data(corrections_name, zhejiang_lines)) +
                           sort_data(jiangsu_dictionary, correct_name_data(corrections_name, jiangsu_lines)) +
                           sort_data(guangdong_dictionary, correct_name_data(corrections_name, guangdong_lines)) +
                           sort_data(hunan_dictionary, correct_name_data(corrections_name, hunan_lines)) +
                           sort_data(beijing_dictionary, correct_name_data(corrections_name, beijing_lines)) +
                           sort_data(shandong_dictionary, correct_name_data(corrections_name, shandong_lines)) + ['\n'])

    # å®šåˆ¶æºçš„ä¸“ä¸šé¢‘é“
    all_lines_custom.extend(["âš½ä½“è‚²é¢‘é“,#genre#"] + sort_data(tiyu_dictionary, correct_name_data(corrections_name, tiyu_lines)) + ['\n'])
    all_lines_custom.extend(["ğŸ†ä½“è‚²èµ›äº‹,#genre#"] + normalized_tiyusaishi_lines + ['\n'])
    all_lines_custom.extend(["ğŸ¬å½±è§†å¨±ä¹,#genre#"] + 
                           sort_data(dianying_dictionary, correct_name_data(corrections_name, dianying_lines)) +
                           sort_data(dianshiju_dictionary, correct_name_data(corrections_name, dianshiju_lines)) +
                           sort_data(zongyi_dictionary, correct_name_data(corrections_name, zongyi_lines)) + ['\n'])
    all_lines_custom.extend(["ğŸ­æ¸¯æ¾³å°,#genre#"] + 
                           sort_data(gangaotai_dictionary, correct_name_data(corrections_name, gangaotai_lines)) +
                           sort_data(xianggang_dictionary, correct_name_data(corrections_name, xianggang_lines)) +
                           sort_data(aomen_dictionary, correct_name_data(corrections_name, aomen_lines)) + ['\n'])
    all_lines_custom.extend(["ğŸ“¦å…¶å®ƒæº,#genre#"] + others_lines + ['\n'])
    all_lines_custom.extend(["ğŸ•’æ›´æ–°æ—¶é—´,#genre#"] + [version, about, daily_mtv, daily_mtv1, daily_mtv2, daily_mtv3, daily_mtv4] + read_txt_to_array(f"{CONFIG['manual_dir']}/about.txt") + ['\n'])

    # å…¶å®ƒæº (others.txt)
    all_lines_others = []
    all_lines_others.extend(["å…¶å®ƒæº,#genre#"] + others_lines + ['\n'])

    # 7. ä¿å­˜å››ä¸ªç‰ˆæœ¬æ–‡ä»¶
    output_data = {
        'full': all_lines_full,
        'lite': all_lines_lite,
        'custom': all_lines_custom,
        'others': all_lines_others
    }

    for file_type, lines in output_data.items():
        file_path = CONFIG['output_files'][file_type]
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write('\n'.join(lines))
            print(f"âœ… {file_type}æºå·²ä¿å­˜: {file_path}")
            
            if os.path.exists(file_path):
                file_size = os.path.getsize(file_path)
                lines_count = len(lines)
                print(f"   ğŸ“Š å¤§å°: {file_size} å­—èŠ‚, è¡Œæ•°: {lines_count}")
                
        except Exception as e:
            print(f"âŒ ä¿å­˜{file_type}æ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")

    # 8. ç”ŸæˆM3Uæ–‡ä»¶
    def get_logo_by_channel_name(channel_name):
        """æ ¹æ®é¢‘é“åç§°è·å–logo"""
        try:
            channels_logos = read_txt_to_array(f"{CONFIG['assets_dir']}/logo.txt")
            for line in channels_logos:
                if not line.strip():
                    continue
                if ',' in line:
                    name, url = line.split(',', 1)
                    if name == channel_name:
                        return url
        except Exception as e:
            print(f"âš ï¸ è·å–logoæ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")
        return None

    def make_m3u(txt_file, m3u_file):
        """ç”ŸæˆM3Uæ–‡ä»¶"""
        try:
            if not os.path.exists(txt_file):
                print(f"âŒ TXTæ–‡ä»¶ä¸å­˜åœ¨: {txt_file}")
                return
                
            output_text = '#EXTM3U x-tvg-url="https://live.fanmingming.cn/e.xml"\n'
            with open(txt_file, "r", encoding='utf-8') as file:
                input_text = file.read()

            lines = input_text.strip().split("\n")
            group_name = ""
            for line in lines:
                parts = line.split(",")
                if len(parts) == 2 and "#genre#" in line:
                    group_name = parts[0]
                elif len(parts) == 2:
                    channel_name = parts[0]
                    channel_url = parts[1]
                    logo_url = get_logo_by_channel_name(channel_name)
                    if logo_url is None:
                        output_text += f'#EXTINF:-1 group-title="{group_name}",{channel_name}\n{channel_url}\n'
                    else:
                        output_text += f'#EXTINF:-1 tvg-name="{channel_name}" tvg-logo="{logo_url}" group-title="{group_name}",{channel_name}\n{channel_url}\n'

            with open(f"{m3u_file}", "w", encoding='utf-8') as file:
                file.write(output_text)
            print(f"âœ… M3Uæ–‡ä»¶ç”Ÿæˆ: {m3u_file}")
        except Exception as e:
            print(f"âŒ ç”ŸæˆM3Uæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯ï¼š{e}")

    # ä¸ºå®Œæ•´ç‰ˆã€ç²¾ç®€ç‰ˆã€å®šåˆ¶ç‰ˆç”Ÿæˆå¯¹åº”çš„M3Uæ–‡ä»¶
    print("ğŸµ ç”ŸæˆM3Uæ–‡ä»¶...")
    make_m3u(CONFIG['output_files']['full'], CONFIG['output_files']['full'].replace(".txt", ".m3u"))
    make_m3u(CONFIG['output_files']['lite'], CONFIG['output_files']['lite'].replace(".txt", ".m3u"))
    make_m3u(CONFIG['output_files']['custom'], CONFIG['output_files']['custom'].replace(".txt", ".m3u"))

    # 9. ç»Ÿè®¡ä¿¡æ¯ - ä½¿ç”¨åŒ—äº¬æ—¶é—´
    timeend = datetime.now(beijing_tz)
    elapsed_time = timeend - timestart
    total_seconds = elapsed_time.total_seconds()
    minutes = int(total_seconds // 60)
    seconds = int(total_seconds % 60)

    print("\nğŸ“Š ======== æ‰§è¡Œç»Ÿè®¡ =======")
    print(f"â° å¼€å§‹æ—¶é—´: {timestart.strftime('%Y-%m-%d %H:%M:%S')} (åŒ—äº¬æ—¶é—´)")
    print(f"â° ç»“æŸæ—¶é—´: {timeend.strftime('%Y-%m-%d %H:%M:%S')} (åŒ—äº¬æ—¶é—´)")
    print(f"â±ï¸ æ‰§è¡Œæ—¶é—´: {minutes}åˆ†{seconds}ç§’")
    print(f"ğŸ“‹ é»‘åå•: {len(combined_blacklist)} æ¡")
    print(f"ğŸ“‹ ç™½åå•: {whitelist_count} ä¸ªé«˜é€Ÿæº")

    # ä¸»é¢‘é“ç»Ÿè®¡
    print(f"ğŸŒ å¤®è§†æº: {len(yangshi_lines)} ä¸ª")
    print(f"ğŸ“¡ å«è§†æº: {len(weishi_lines)} ä¸ª")

    # åœ°æ–¹å°ç»Ÿè®¡
    print(f"ğŸ  åŒ—äº¬æº: {len(beijing_lines)} ä¸ª")
    print(f"ğŸ  ä¸Šæµ·æº: {len(shanghai_lines)} ä¸ª")
    print(f"ğŸ  å¤©æ´¥æº: {len(tianjin_lines)} ä¸ª")
    print(f"ğŸ  é‡åº†æº: {len(chongqing_lines)} ä¸ª")
    print(f"ğŸ  å¹¿ä¸œæº: {len(guangdong_lines)} ä¸ª")
    print(f"ğŸ  æ±Ÿè‹æº: {len(jiangsu_lines)} ä¸ª")
    print(f"ğŸ  æµ™æ±Ÿæº: {len(zhejiang_lines)} ä¸ª")
    print(f"ğŸ  å±±ä¸œæº: {len(shandong_lines)} ä¸ª")
    print(f"ğŸ  æ²³å—æº: {len(henan_lines)} ä¸ª")
    print(f"ğŸ  å››å·æº: {len(sichuan_lines)} ä¸ª")
    print(f"ğŸ  æ²³åŒ—æº: {len(hebei_lines)} ä¸ª")
    print(f"ğŸ  æ¹–å—æº: {len(hunan_lines)} ä¸ª")
    print(f"ğŸ  æ¹–åŒ—æº: {len(hubei_lines)} ä¸ª")
    print(f"ğŸ  å®‰å¾½æº: {len(anhui_lines)} ä¸ª")
    print(f"ğŸ  ç¦å»ºæº: {len(fujian_lines)} ä¸ª")
    print(f"ğŸ  é™•è¥¿æº: {len(shanxi1_lines)} ä¸ª")
    print(f"ğŸ  è¾½å®æº: {len(liaoning_lines)} ä¸ª")
    print(f"ğŸ  æ±Ÿè¥¿æº: {len(jiangxi_lines)} ä¸ª")
    print(f"ğŸ  é»‘é¾™æ±Ÿæº: {len(heilongjiang_lines)} ä¸ª")
    print(f"ğŸ  å‰æ—æº: {len(jilin_lines)} ä¸ª")
    print(f"ğŸ  å±±è¥¿æº: {len(shanxi2_lines)} ä¸ª")
    print(f"ğŸ  å¹¿è¥¿æº: {len(guangxi_lines)} ä¸ª")
    print(f"ğŸ  äº‘å—æº: {len(yunnan_lines)} ä¸ª")
    print(f"ğŸ  è´µå·æº: {len(guizhou_lines)} ä¸ª")
    print(f"ğŸ  ç”˜è‚ƒæº: {len(gansu_lines)} ä¸ª")
    print(f"ğŸ  å†…è’™æº: {len(neimenggu_lines)} ä¸ª")
    print(f"ğŸ  æ–°ç–†æº: {len(xinjiang_lines)} ä¸ª")
    print(f"ğŸ  æµ·å—æº: {len(hainan_lines)} ä¸ª")
    print(f"ğŸ  å®å¤æº: {len(ningxia_lines)} ä¸ª")
    print(f"ğŸ  é’æµ·æº: {len(qinghai_lines)} ä¸ª")
    print(f"ğŸ  è¥¿è—æº: {len(xizang_lines)} ä¸ª")

    # ä¸“ä¸šé¢‘é“ç»Ÿè®¡
    print(f"ğŸ“° æ–°é—»é¢‘é“: {len(news_lines)} ä¸ª")
    print(f"ğŸï¸ æ•°å­—é¢‘é“: {len(shuzi_lines)} ä¸ª")
    print(f"ğŸ¬ ç”µå½±é¢‘é“: {len(dianying_lines)} ä¸ª")
    print(f"ğŸ™ï¸ è§£è¯´é¢‘é“: {len(jieshuo_lines)} ä¸ª")
    print(f"ğŸ¤ ç»¼è‰ºé¢‘é“: {len(zongyi_lines)} ä¸ª")
    print(f"ğŸ¯ è™ç‰™ç›´æ’­: {len(huya_lines)} ä¸ª")
    print(f"ğŸ¬ æ–—é±¼ç›´æ’­: {len(douyu_lines)} ä¸ª")
    print(f"ğŸ‡­ğŸ‡° é¦™æ¸¯é¢‘é“: {len(xianggang_lines)} ä¸ª")
    print(f"ğŸ‡²ğŸ‡´ æ¾³é—¨é¢‘é“: {len(aomen_lines)} ä¸ª")
    print(f"ğŸ‡¨ğŸ‡³ ä¸­å›½é¢‘é“: {len(china_lines)} ä¸ª")
    print(f"ğŸŒ å›½é™…é¢‘é“: {len(guoji_lines)} ä¸ª")
    print(f"ğŸ‡¨ğŸ‡³ æ¸¯æ¾³å°: {len(gangaotai_lines)} ä¸ª")
    print(f"ğŸ“º ç”µè§†å‰§: {len(dianshiju_lines)} ä¸ª")
    print(f"ğŸ“» æ”¶éŸ³æœº: {len(radio_lines)} ä¸ª")
    print(f"ğŸ• åŠ¨ç”»ç‰‡: {len(donghuapian_lines)} ä¸ª")
    print(f"ğŸ“½ï¸ è®°å½•ç‰‡: {len(jilupian_lines)} ä¸ª")
    print(f"âš½ ä½“è‚²é¢‘é“: {len(tiyu_lines)} ä¸ª")
    print(f"ğŸ† ä½“è‚²èµ›äº‹: {len(normalized_tiyusaishi_lines)} ä¸ª")
    print(f"ğŸ® æ¸¸æˆé¢‘é“: {len(youxi_lines)} ä¸ª")
    print(f"ğŸ­ æˆæ›²é¢‘é“: {len(xiqu_lines)} ä¸ª")
    print(f"ğŸµ éŸ³ä¹é¢‘é“: {len(yinyue_lines)} ä¸ª")
    print(f"ğŸ‰ æ˜¥æ™šé¢‘é“: {len(chunwan_lines)} ä¸ª")
    print(f"ğŸ“¡ ç›´æ’­ä¸­å›½: {len(zhibozhongguo_lines)} ä¸ª")

    # å…¶ä»–ç»Ÿè®¡
    print(f"ğŸš€ AKTV: {len(aktv_lines)} ä¸ª")
    print(f"ğŸ“¦ å…¶å®ƒæº: {len(others_lines)} ä¸ª")
    print(f"ğŸ“„ å…¨éƒ¨æº: {len(all_lines_full)} è¡Œ")
    print(f"ğŸ“„ ç²¾ç®€æº: {len(all_lines_lite)} è¡Œ")
    print(f"ğŸ“„ å®šåˆ¶æº: {len(all_lines_custom)} è¡Œ")
    print("======================\n")

    # æœ€ç»ˆæ£€æŸ¥æ‰€æœ‰è¾“å‡ºæ–‡ä»¶
    print("ğŸ” æœ€ç»ˆæ–‡ä»¶æ£€æŸ¥:")
    all_files_ok = True
    for file_type, file_path in CONFIG['output_files'].items():
        if os.path.exists(file_path):
            file_size = os.path.getsize(file_path)
            status = "âœ…" if file_size > 0 else "âŒ"
            print(f"  {status} {file_type}: {file_path} ({file_size} å­—èŠ‚)")
            if file_size == 0:
                all_files_ok = False
        else:
            print(f"  âŒ {file_type}: {file_path} (æ–‡ä»¶ä¸å­˜åœ¨)")
            all_files_ok = False

    # æ£€æŸ¥M3Uæ–‡ä»¶
    for file_type in ['full', 'lite', 'custom']:
        m3u_file = CONFIG['output_files'][file_type].replace(".txt", ".m3u")
        if os.path.exists(m3u_file):
            file_size = os.path.getsize(m3u_file)
            status = "âœ…" if file_size > 0 else "âŒ"
            print(f"  {status} {file_type}.m3u: {m3u_file} ({file_size} å­—èŠ‚)")
        else:
            print(f"  âŒ {file_type}.m3u: {m3u_file} (æ–‡ä»¶ä¸å­˜åœ¨)")
            all_files_ok = False

    if all_files_ok:
        print("ğŸ‰ æ‰€æœ‰æ–‡ä»¶ç”ŸæˆæˆåŠŸï¼")
    else:
        print("âš ï¸ éƒ¨åˆ†æ–‡ä»¶ç”Ÿæˆæœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼")

if __name__ == "__main__":
    main()